{"cells":[{"cell_type":"markdown","source":["**URL** - это ссылка на видео из задания  \n","**frame** - кадр из задания  \n","**class_object** - посмотри видео и напиши самый большой обьект на английском."],"metadata":{"id":"UcMDw0SHjxsG"}},{"cell_type":"code","source":["#@title Что-то меняем...\n","URL = \"https://courses.openedu.ru/assets/courseware/v1/08df7bdc1d63d74835e9797804d5708d/asset-v1:ITMOUniversity+COMPVIS+spring_2022_ITMO+type@asset+block/var_MOT17-10-SDP_2.mp4\" #@param {type:\"string\"}\n","frame =  73#@param {type:\"integer\"}\n","class_object = \"airplane\" #@param {type:\"string\"}\n","\n","video_name = URL.split(\"/\")[-1]\n","print(f\"video_name = {video_name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFWETcF8Ym2u","executionInfo":{"status":"ok","timestamp":1652365240832,"user_tz":-180,"elapsed":29,"user":{"displayName":"Алексей Горбатовский","userId":"04783083227935562407"}},"outputId":"eb828da6-9bf1-465b-fba5-6dc8c39e53bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["video_name = var_MOT17-10-SDP_2.mp4\n"]}]},{"cell_type":"markdown","source":["Скачай файл видео:"],"metadata":{"id":"dxJNOgAsh5cw"}},{"cell_type":"code","source":["!wget \"https://courses.openedu.ru/assets/courseware/v1/5dab01488703c262d33ed6a5ef074a71/asset-v1:ITMOUniversity+COMPVIS+spring_2022_ITMO+type@asset+block/var_MOT17-04-SDP_4.mp4\""],"metadata":{"id":"bN3LrrLrZLrg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652358915782,"user_tz":-180,"elapsed":1970,"user":{"displayName":"Алексей Горбатовский","userId":"04783083227935562407"}},"outputId":"e6bb1f47-4a31-4114-f417-c80de86641a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-12 12:35:13--  https://courses.openedu.ru/assets/courseware/v1/5dab01488703c262d33ed6a5ef074a71/asset-v1:ITMOUniversity+COMPVIS+spring_2022_ITMO+type@asset+block/var_MOT17-04-SDP_4.mp4\n","Resolving courses.openedu.ru (courses.openedu.ru)... 178.248.235.109\n","Connecting to courses.openedu.ru (courses.openedu.ru)|178.248.235.109|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://cdn.openedu.ru/ESZCBLZ/courseware/v1/5dab01488703c262d33ed6a5ef074a71/asset-v1:ITMOUniversity+COMPVIS+spring_2022_ITMO+type@asset+block/var_MOT17-04-SDP_4.mp4 [following]\n","--2022-05-12 12:35:14--  https://cdn.openedu.ru/ESZCBLZ/courseware/v1/5dab01488703c262d33ed6a5ef074a71/asset-v1:ITMOUniversity+COMPVIS+spring_2022_ITMO+type@asset+block/var_MOT17-04-SDP_4.mp4\n","Resolving cdn.openedu.ru (cdn.openedu.ru)... 212.193.146.51\n","Connecting to cdn.openedu.ru (cdn.openedu.ru)|212.193.146.51|:443... failed: Connection refused.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvKhKKi9YLs7"},"outputs":[],"source":["#@title ПРОСТО ЗАПУСТИ МЕНЯ!!!\n","!pip install filterpy 1>/dev/null 2>/dev/null\n","\n","import numpy as np\n","import cv2\n","import random\n","\n","try:\n","  from numba import jit\n","except:\n","  def jit(func):\n","    return func\n","\n","np.random.seed(0)\n","\n","from filterpy.kalman import KalmanFilter\n","\n","def linear_assignment(cost_matrix):\n","  try:\n","    import lap\n","    _, x, y = lap.lapjv(cost_matrix, extend_cost=True)\n","    return np.array([[y[i],i] for i in x if i >= 0]) #\n","  except ImportError:\n","    from scipy.optimize import linear_sum_assignment\n","    x, y = linear_sum_assignment(cost_matrix)\n","    return np.array(list(zip(x, y)))\n","\n","\n","@jit\n","def iou(bb_test, bb_gt):\n","  \"\"\"\n","  Computes IUO between two bboxes in the form [x1,y1,x2,y2]\n","  \"\"\"\n","  xx1 = np.maximum(bb_test[0], bb_gt[0])\n","  yy1 = np.maximum(bb_test[1], bb_gt[1])\n","  xx2 = np.minimum(bb_test[2], bb_gt[2])\n","  yy2 = np.minimum(bb_test[3], bb_gt[3])\n","  w = np.maximum(0., xx2 - xx1)\n","  h = np.maximum(0., yy2 - yy1)\n","  wh = w * h\n","  o = wh / ((bb_test[2] - bb_test[0]) * (bb_test[3] - bb_test[1])\n","    + (bb_gt[2] - bb_gt[0]) * (bb_gt[3] - bb_gt[1]) - wh)\n","  return(o)\n","\n","\n","def convert_bbox_to_z(bbox):\n","  \"\"\"\n","  Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n","    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n","    the aspect ratio\n","  \"\"\"\n","  w = bbox[2] - bbox[0]\n","  h = bbox[3] - bbox[1]\n","  x = bbox[0] + w/2.\n","  y = bbox[1] + h/2.\n","  s = w * h    #scale is just area\n","  r = w / float(h)\n","  return np.array([x, y, s, r]).reshape((4, 1))\n","\n","\n","def convert_x_to_bbox(x,score=None):\n","  \"\"\"\n","  Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n","    [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n","  \"\"\"\n","  w = np.sqrt(x[2] * x[3])\n","  h = x[2] / w\n","  if(score==None):\n","    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n","  else:\n","    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n","\n","\n","class KalmanBoxTracker(object):\n","  \"\"\"\n","  This class represents the internal state of individual tracked objects observed as bbox.\n","  \"\"\"\n","  count = 0\n","  def __init__(self,bbox):\n","    \"\"\"\n","    Initialises a tracker using initial bounding box.\n","    \"\"\"\n","    #define constant velocity model\n","    self.kf = KalmanFilter(dim_x=7, dim_z=4) \n","    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n","    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n","\n","    self.kf.R[2:,2:] *= 10.\n","    self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n","    self.kf.P *= 10.\n","    self.kf.Q[-1,-1] *= 0.01\n","    self.kf.Q[4:,4:] *= 0.01\n","\n","    self.kf.x[:4] = convert_bbox_to_z(bbox)\n","    self.time_since_update = 0\n","    self.id = KalmanBoxTracker.count\n","    KalmanBoxTracker.count += 1\n","    self.history = []\n","    self.hits = 0\n","    self.hit_streak = 0\n","    self.age = 0\n","\n","  def update(self,bbox):\n","    \"\"\"\n","    Updates the state vector with observed bbox.\n","    \"\"\"\n","    self.time_since_update = 0\n","    self.history = []\n","    self.hits += 1\n","    self.hit_streak += 1\n","    self.kf.update(convert_bbox_to_z(bbox))\n","\n","  def predict(self):\n","    \"\"\"\n","    Advances the state vector and returns the predicted bounding box estimate.\n","    \"\"\"\n","    if((self.kf.x[6]+self.kf.x[2])<=0):\n","      self.kf.x[6] *= 0.0\n","    self.kf.predict()\n","    self.age += 1\n","    if(self.time_since_update>0):\n","      self.hit_streak = 0\n","    self.time_since_update += 1\n","    self.history.append(convert_x_to_bbox(self.kf.x))\n","    return self.history[-1]\n","\n","  def get_state(self):\n","    \"\"\"\n","    Returns the current bounding box estimate.\n","    \"\"\"\n","    return convert_x_to_bbox(self.kf.x)\n","\n","\n","def associate_detections_to_trackers(detections,trackers,iou_threshold = 0.3):\n","  \"\"\"\n","  Assigns detections to tracked object (both represented as bounding boxes)\n","  Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n","  \"\"\"\n","  if(len(trackers)==0):\n","    return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n","  iou_matrix = np.zeros((len(detections),len(trackers)),dtype=np.float32)\n","\n","  for d,det in enumerate(detections):\n","    for t,trk in enumerate(trackers):\n","      iou_matrix[d,t] = iou(det,trk)\n","\n","  if min(iou_matrix.shape) > 0:\n","    a = (iou_matrix > iou_threshold).astype(np.int32)\n","    if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n","        matched_indices = np.stack(np.where(a), axis=1)\n","    else:\n","      matched_indices = linear_assignment(-iou_matrix)\n","  else:\n","    matched_indices = np.empty(shape=(0,2))\n","\n","  unmatched_detections = []\n","  for d, det in enumerate(detections):\n","    if(d not in matched_indices[:,0]):\n","      unmatched_detections.append(d)\n","  unmatched_trackers = []\n","  for t, trk in enumerate(trackers):\n","    if(t not in matched_indices[:,1]):\n","      unmatched_trackers.append(t)\n","\n","  #filter out matched with low IOU\n","  matches = []\n","  for m in matched_indices:\n","    if(iou_matrix[m[0], m[1]]<iou_threshold):\n","      unmatched_detections.append(m[0])\n","      unmatched_trackers.append(m[1])\n","    else:\n","      matches.append(m.reshape(1,2))\n","  if(len(matches)==0):\n","    matches = np.empty((0,2),dtype=int)\n","  else:\n","    matches = np.concatenate(matches,axis=0)\n","\n","  return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n","\n","\n","class Sort(object):\n","  def __init__(self, max_age=1, min_hits=3):\n","    \"\"\"\n","    Sets key parameters for SORT\n","    \"\"\"\n","    self.max_age = max_age\n","    self.min_hits = min_hits\n","    self.trackers = []\n","    self.frame_count = 0\n","\n","  def update(self, dets=np.empty((0, 5))):\n","    \"\"\"\n","    Params:\n","      dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n","    Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n","    Returns the a similar array, where the last column is the object ID.\n","    NOTE: The number of objects returned may differ from the number of detections provided.\n","    \"\"\"\n","    self.frame_count += 1\n","    # get predicted locations from existing trackers.\n","    trks = np.zeros((len(self.trackers), 5))\n","    to_del = []\n","    ret = []\n","    for t, trk in enumerate(trks):\n","      pos = self.trackers[t].predict()[0]\n","      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n","      if np.any(np.isnan(pos)):\n","        to_del.append(t)\n","    trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n","    for t in reversed(to_del):\n","      self.trackers.pop(t)\n","    matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets,trks)\n","\n","    # update matched trackers with assigned detections\n","    for m in matched:\n","      self.trackers[m[1]].update(dets[m[0], :])\n","\n","    # create and initialise new trackers for unmatched detections\n","    for i in unmatched_dets:\n","        trk = KalmanBoxTracker(dets[i,:])\n","        self.trackers.append(trk)\n","    i = len(self.trackers)\n","    for trk in reversed(self.trackers):\n","        d = trk.get_state()[0]\n","        if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n","          ret.append(np.concatenate((d,[trk.id+1])).reshape(1,-1)) # +1 as MOT benchmark requires positive\n","        i -= 1\n","        # remove dead tracklet\n","        if(trk.time_since_update > self.max_age):\n","          self.trackers.pop(i)\n","    if(len(ret)>0):\n","      return np.concatenate(ret)\n","    return np.empty((0,5))\n","\n","import os\n","from os.path import exists, join, basename, splitext\n","if not exists('yolov3.weights'):\n","  !wget -q  https://pjreddie.com/media/files/yolov3.weights\n","if not exists('yolov3.cfg'):\n","  !wget -q https://github.com/pjreddie/darknet/raw/master/cfg/yolov3.cfg  \n","if not exists('coco.names'):\n","  !wget -q https://github.com/pjreddie/darknet/raw/master/data/coco.names\n","\n","def load_class_names(namesfile):\n","    class_names = []\n","    with open(namesfile, 'r') as fp:\n","        lines = fp.readlines()\n","    for line in lines:\n","        line = line.rstrip()\n","        class_names.append(line)\n","    return class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cpnwRuR-YLtB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652365544837,"user_tz":-180,"elapsed":230501,"user":{"displayName":"Алексей Горбатовский","userId":"04783083227935562407"}},"outputId":"3c0c9590-32b4-4c18-c759-28b2d8d0e3a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["person : 0.9975242018699646\n","x = 1589, y = 293\n","Ширина = 189, Высота = 621\n","\n","person : 0.9887861609458923\n","x = 1052, y = 316\n","Ширина = 66, Высота = 187\n","\n","person : 0.9794845581054688\n","x = 1804, y = 302\n","Ширина = 116, Высота = 602\n","\n","person : 0.9747881889343262\n","x = 803, y = 348\n","Ширина = 47, Высота = 110\n","\n","person : 0.9549583792686462\n","x = 902, y = 342\n","Ширина = 72, Высота = 164\n","\n","person : 0.9539835453033447\n","x = 723, y = 340\n","Ширина = 51, Высота = 122\n","\n","person : 0.9240983128547668\n","x = 541, y = 348\n","Ширина = 61, Высота = 115\n","\n","person : 0.8904576301574707\n","x = 852, y = 352\n","Ширина = 36, Высота = 99\n","\n","bench : 0.8610988855361938\n","x = 447, y = 645\n","Ширина = 660, Высота = 405\n","\n","person : 0.7830045223236084\n","x = 238, y = 368\n","Ширина = 49, Высота = 116\n","\n","bench : 0.5991846919059753\n","x = 441, y = 429\n","Ширина = 129, Высота = 80\n","\n","person : 0.5508096218109131\n","x = 413, y = 355\n","Ширина = 32, Высота = 103\n","\n","Frames in video: 100\n","Max detections: 15\n","Max classes: 3\n"]}],"source":["#@title Запусти теперь меня и получи ответы :)\n","# Загружаем сеть\n","net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n","ln = net.getLayerNames()\n","ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","# Инициализируем трекер\n","mot_tracker = Sort()\n","# Используем YOLO\n","namesfile = 'coco.names'\n","class_names = load_class_names(namesfile)\n","# Указываем необходимый видео-файл\n","cap = cv2.VideoCapture(video_name)\n","# Указываем кодеки для результирующего видео\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","videoWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","videoHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","# Определяем результирующее видео\n","out = cv2.VideoWriter('output_SORT.avi',fourcc, 20.0,(videoWidth,videoHeight))\n","# Генерируем будующим прямоугольникам разные цвета\n","color_list = []\n","for j in range(1000):\n","  color_list.append(((int)(random.randrange(255)),(int)(random.randrange(255)),(int)(random.randrange(255))))\n","\n","kk = 0 \n","ret = True\n","max_detections = 0\n","max_classes = 0\n","while ret:\n","    ret, img = cap.read()\n","    if ret:\n","        # Запустим сеть по кадру\n","        blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n","        h,w,_ = img.shape\n","        net.setInput(blob)\n","        layerOutputs = net.forward(ln)\n","        # Разберём все выходы\n","        boxes=[]\n","        confidences=[]\n","        classIDs=[]\n","        for output in layerOutputs:\n","            for detection in output:\n","                scores = detection[5:]\n","                classID = np.argmax(scores)\n","                confidence = scores[classID]\n","                if confidence > 0.5:\n","                    box = detection[0:4] * np.array([w, h, w, h])\n","                    (centerX, centerY, width, height) = box.astype(\"int\")\n","                    x = int(centerX - (width / 2))\n","                    y = int(centerY - (height / 2))\n","                    boxes.append([x, y, int(width), int(height)])\n","                    confidences.append(float(confidence))\n","                    classIDs.append(classID)\n","\n","        idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n","        result_img = np.copy(img)\n","        dets = []\n","        count_detection = 0\n","        total_count_detection = 0\n","        classes = set()\n","        for j in range(len(idxs)):\n","            name = class_names[classIDs[idxs[j][0]]]\n","            if name == class_object:\n","                count_detection+=1\n","            total_count_detection += 1\n","            classes.add(name)\n","        if total_count_detection > 0:\n","            detects = np.zeros((count_detection,5))\n","            count=0\n","            # Формат, необходимый для трекера\n","            for j in range(len(idxs)):\n","                b = boxes[idxs[j][0]]\n","                name = class_names[classIDs[idxs[j][0]]]\n","                x1 = int(b[0])\n","                y1 = int(b[1])\n","                x2 = int((b[0] + b[2]))\n","                y2 = int((b[1] + b[3]))\n","                if name == class_object: # указываем необходимую метку для объектов\n","                  box = np.array([x1,y1,x2,y2,confidences[idxs[j][0]]])\n","                  detects[count,:] = box[:]\n","                  count+=1\n","                if (kk == frame):\n","                  print(f\"{name} : {confidences[idxs[j][0]]}\")\n","                  print(f\"x = {x1}, y = {y1}\")\n","                  print(f\"Ширина = {x2 - x1}, Высота = {y2 - y1}\\n\")\n","            # Парсим данные трекера\n","            if len(detects) != 0:\n","                trackers = mot_tracker.update(detects)\n","                index = 0\n","                for d in trackers:\n","                  # if (kk == frame):\n","                    # print()\n","                    # print(name, \": \", end=\"\")\n","                    # print(confidences[idxs[index][0]])\n","                    # print((int(d[0]), int(d[1])), (int(d[2] - d[0]), (int(d[3] - d[1]))))\n","                  result_img = cv2.rectangle(result_img, ((int)(d[0]), (int)(d[1])), ((int)(d[2]), (int)(d[3])), color_list[0], 2)\n","                  result_img = cv2.putText(result_img, name + \"-\" + str(round(confidences[idxs[index][0]], 3)), ((int)(d[0]), (int)(d[1]) - 10), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, color_list[0], 2)\n","                  index += 1\n","        out.write(result_img) # пишем кадр в результирующее видео\n","        if (kk == frame):\n","            cv2.imwrite(f'frame_{frame}.png', result_img)\n","        kk += 1\n","        if (total_count_detection > max_detections):\n","            max_detections = total_count_detection\n","        if (len(classes) > max_classes):\n","            max_classes = len(classes)\n","    else: \n","        break\n","print(f\"Frames in video: {kk}\")\n","print(f\"Max detections: {max_detections}\")\n","print(f\"Max classes: {max_classes}\")\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","source":[""],"metadata":{"id":"eN2oHc8qQiK9"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"week4.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}